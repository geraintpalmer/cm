{"nbformat": 4, "nbformat_minor": 2, "cells": [{"source": ["---\n", "layout: page\n", "permalink: /chapters/session10/\n", "---"], "cell_type": "raw", "metadata": {}}, {"source": ["## Goals\n", "+ Gain an awareness of Python libraries, their uses and potentials.\n", "+ Be able to install (where appropriate) and import libraries.\n", "+ Practise using and writing code using these libraries."], "cell_type": "markdown", "metadata": {}}, {"source": ["## Libraries\n", "\n", "In Python, libraries are packages of pre-written code that usually contain functions and objects that can be imported into your own code. They are usually very efficient implementations of algorithms, models and procedures. In general if there is a library that does something you yourself would like to implement, it is better to use the library as it is probably well written, veified and tests, and efficient.\n", "\n", "In this course you have already used some libraries, [Ciw](https://ciw.readthedocs.io/en/latest/) for simulating queueing systems, [networkx](https://networkx.github.io/) for networks, [numpy](https://www.numpy.org/) was used to reading in file (but is used for much more than this!), [random](https://docs.python.org/2/library/random.html) for generating random numbers, and [math](https://docs.python.org/3/library/math.html) for mathematical operations and constants.\n", "\n", "There are two kinds of Python library:\n", "\n", "  + Those in the standard Python library (e.g. `math`), these come pre-installed every distribution of Python. There is no need to install these libraries. Many are written by the same people who write Python itself.\n", "  + Those not in the standard Python library (e.g. Ciw). In order to use these you will have to install them seperately uring `pip`.\n", "\n", "Having said this, in this course we are using an Anaconda distribution of Python, which comes pre-installed with a number of popular libraries that are not in the standard Python library.\n", "\n", "This tutorial is a demonstration of the uses of a number of libraries you may find useful during your studies. We will look at:\n", "\n", "  + [`numpy`](https://www.numpy.org/) for matrix and numerical operations,\n", "  + [`matplotlib`](https://matplotlib.org/) for creating plots,\n", "  + [`pandas`](https://pandas.pydata.org/) for data analysis,\n", "  + [`scipy`](https://www.scipy.org/scipylib/index.html) for statistical testing and other scientific procedures,\n", "  + [`scikit-learn`](https://scikit-learn.org/) for machine learning."], "cell_type": "markdown", "metadata": {}}, {"source": ["# Numpy\n", "\n", "The power of this library is its efficiency in carrying out numeric computations, especially linear algebraic manipulation.\n", "\n", "For example consider two matrices:\n", "\n", "$\\mathbf{A} = \\begin{pmatrix}3&4&-2\\\\2&1&-1\\\\7&-10&-5\\end{pmatrix}$\n", "\n", "and\n", "\n", "$\\mathbf{B} = \\begin{pmatrix}1&5&4\\end{pmatrix}$\n", "\n", "in numpy:"], "cell_type": "markdown", "metadata": {}}, {"source": ["import numpy as np\n", "\n", "A = np.array([[3, 4, -2], [2, 1, -1], [7, -10, -5]])\n", "A"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 1}, {"source": ["B = np.array([[1, 5, 4]])\n", "B"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 2}, {"source": ["We can access the various elements of these matrices using indexing (like we have seen before with lists):"], "cell_type": "markdown", "metadata": {}}, {"source": ["A[0]"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 3}, {"source": ["A[0][2]"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 4}, {"source": ["But also, a more efficent way to index is to use numpy indexing, like so:"], "cell_type": "markdown", "metadata": {}}, {"source": ["A[0, 1]"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 5}, {"source": ["We can perform scalar multiplication:"], "cell_type": "markdown", "metadata": {}}, {"source": ["5 * A"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 6}, {"source": ["Raise to powers:"], "cell_type": "markdown", "metadata": {}}, {"source": ["np.linalg.matrix_power(A, 26)"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 7}, {"source": ["Perform matrix addition:"], "cell_type": "markdown", "metadata": {}}, {"source": ["A + A"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 8}, {"source": ["And multiplication:"], "cell_type": "markdown", "metadata": {}}, {"source": ["np.matmul(B, A)"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 9}, {"source": ["And further linear algebraic manipulation, such as determinants and inverses:"], "cell_type": "markdown", "metadata": {}}, {"source": ["np.linalg.det(A)"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 10}, {"source": ["np.linalg.inv(A)"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 11}, {"source": ["np.matmul(A, np.linalg.inv(A))"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 12}, {"source": ["Numpy is also useful in other contexts, for example to create arrays of equally spaced numbers:"], "cell_type": "markdown", "metadata": {}}, {"source": ["# 20 numbers between 4 and 10:\n", "np.linspace(4, 10, 20)"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 13}, {"source": ["# Or an array of numbers starting from 0, with space 0.2, ending at 30:\n", "np.arange(0, 30, 0.2)"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 14}, {"source": ["# Matplotlib\n", "\n", "This is the most popular Python library for producing plots. It is flexible enough to be able to create nearly most plots you will require in most styles, and it also has a simpler interface, pyplot, for quick and easy plotting.\n", "\n", "We'll demonstrate trhough examples.\n", "\n", "Before we begin, *in order for plots to display in Jupyter*, we need the follwing line of code (this is *only* needed in Jupyter):"], "cell_type": "markdown", "metadata": {}}, {"source": ["%matplotlib inline"], "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "execution_count": 15}, {"source": ["Next we'll import pyplot, and create a line plot:"], "cell_type": "markdown", "metadata": {}}, {"source": ["import matplotlib.pyplot as plt\n", "\n", "x_vals = [1, 2, 3.5, 7, 8, 8.5, 9]\n", "y_vals = [-1.2, -1.1, 4, 3.5, 5.7, 5.7, 6]\n", "\n", "plt.plot(x_vals, y_vals)\n", "plt.show()"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 16}, {"source": ["![](/assets/lineplot.png)"], "cell_type": "markdown", "metadata": {}}, {"source": ["Using the same data, we can make a scatterplot (and let's customise it a little):"], "cell_type": "markdown", "metadata": {}}, {"source": ["plt.scatter(x_vals, y_vals, c='red', s=150, marker='x')\n", "plt.show()"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 18}, {"source": ["![](/assets/scatter.png)"], "cell_type": "markdown", "metadata": {}}, {"source": ["A vast number of other types of plot can be produced which can't all be listed here. Below are examples of creating histograms and boxplots. First some random data is created (using the `random` library from the standard Python library):"], "cell_type": "markdown", "metadata": {}}, {"source": ["import random\n", "data = [random.lognormvariate(0.85, 0.45) for _ in range(350)]"], "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "execution_count": 20}, {"source": ["plt.hist(data)\n", "plt.show()"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 21}, {"source": ["![](/assets/hist.png)"], "cell_type": "markdown", "metadata": {}}, {"source": ["plt.boxplot(data)\n", "plt.show()"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 23}, {"source": ["![](/assets/boxplot.png)"], "cell_type": "markdown", "metadata": {}}, {"source": ["Finally matplotlib allows plots to be combined, customised and saved in a number of formats (experiment with .png, .svg and .pdf):"], "cell_type": "markdown", "metadata": {}}, {"source": ["plt.style.use('seaborn-whitegrid')\n", "plt.hist(data, alpha=0.7, color='darkorange', edgecolor='black', bins=[i*0.5 for i in range(21)])\n", "plt.ylabel('Frequency', fontsize=16)\n", "plt.xlabel('Values', fontsize=20)\n", "plt.title('My Histogram', fontsize=24)\n", "plt.xlim(0, 10)\n", "plt.savefig('histogram.pdf')"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 25}, {"source": ["![](/assets/histogram.png)"], "cell_type": "markdown", "metadata": {}}, {"source": ["# Pandas"], "cell_type": "markdown", "metadata": {}}, {"source": ["Pandas is Python's most popular library for data analysis and data manipulation. It is very useful for storing data in objects called 'data frames', which arrange data into useful and meaningful rows and columns. These data frames can be manipulated very efficiently for reshaping data, and performing data analyses on them.\n", "\n", "To show an example, let's read in a csv file (it can be downloaded from [here](/assets/titanic.csv) if you're following along), data of passengers on the Titanic:"], "cell_type": "markdown", "metadata": {}}, {"source": ["import pandas as pd\n", "data = pd.read_csv('titanic.csv')"], "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "execution_count": 27}, {"source": ["And look at the first few rows:"], "cell_type": "markdown", "metadata": {}}, {"source": ["{% highlight python %}\n", ">>> data.head()\n", "{% endhighlight %}\n", "\n", "![](/assets/pandas-head.png)"], "cell_type": "raw", "metadata": {}}, {"source": ["We can see that this data has 4 columns, the passengers' name, their cabin class, their age and sex, and whether they survived or not.\n", "\n", "We'll use this to demonstrate some of pandas' data manipulation methods."], "cell_type": "markdown", "metadata": {}}, {"source": ["len(data) # number of observations (rows)"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 29}, {"source": ["{% highlight python %}\n", ">>> data.describe()  # Descriptive statistics for each numerical column of the data frame\n", "{% endhighlight %}\n", "\n", "![](/assets/pandas-describe.png)"], "cell_type": "raw", "metadata": {}}, {"source": ["data['Age'].head()  # just the 'Age' column (.head is used to get only the first 5 rows, to make the output easier to read)"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 31}, {"source": ["data['PClass'].value_counts()  # Couting the number of each value in the 'PClass' column"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 32}, {"source": ["data.groupby('PClass')['Age'].mean()  # The mean value of the 'Age' column for each unique value in the 'PClass' column"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 33}, {"source": ["{% highlight python %}\n", ">>> data[data['Age'] > 65]  # Filtering only those rows whose 'Age' value is greater than 65\n", "{% endhighlight %}\n", "\n", "![](/assets/pandas-filter.png)"], "cell_type": "raw", "metadata": {}}, {"source": ["As you have seen above some of these methods can be combined, and pandas is very efficient at doing this.\n", "Sometimes simply reshaping data can give valuable insights, for example:"], "cell_type": "markdown", "metadata": {}}, {"source": ["data.groupby('PClass')['Survived'].mean()"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 35}, {"source": ["This gives the mean value of the 'Survived' column for each cabin class, that is for each value in the 'PClass' column. Knowing that 'Survived' is binary, its mean value is the proportion of passengers who survived.\n", "\n", "Therefore by combining `groupby` and `mean` methods on the relevant columns, we can instantly see that there is a relationship between proportion of survivors and cabin class, with the lower cabin classes having a lower proportion of survivors."], "cell_type": "markdown", "metadata": {}}, {"source": ["# Scipy\n", "\n", "This scipy library is very versatile and has a number of functions and methods for conducting scientific procedures and algorithms. It is vast and has a number of specialised sublibraries. We'll look at two of those here:\n", "\n", "  + `scipy.stats` has a number of statistical functions for performing statistical tests and using probability distributions.\n", "  + `scipy.optimize` has a number of algorithms for optimizing functions and curve-fitting.\n", "\n", "\n", "Let's use the Titanic data from above and consider it as a sample (it isn't, it's a population, but let's consider it as a sample for the sake of demonstrating hypothesis testing). Let's see if the average age of female passengers was equal to the average age of male passengers; using a independent sample t-test at the 1% level:"], "cell_type": "markdown", "metadata": {}}, {"source": ["import scipy.stats\n", "female_ages = data[data['Sex']=='female']['Age'].dropna()\n", "male_ages = data[data['Sex']=='male']['Age'].dropna()\n", "scipy.stats.ttest_ind(female_ages, male_ages)"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 36}, {"source": ["A t-test was performed:\n", "\n", "  + $H_0$: The mean age of female passengers is equal to the mean age of male passengers.\n", "  + $H_1$: The mean age of female passengers is not equal to the mean age of male passengers.\n", "  \n", "We obtained a p-value of $0.12385\\dots$, and so at the 1% level the null hypothesis cannot be rejected, and there is not enough evidence to say that the mean ages of the genders differ.\n", "\n", "Scipy also allows non-parametric tests if the observed data is not Normally distributed:"], "cell_type": "markdown", "metadata": {}}, {"source": ["scipy.stats.mannwhitneyu(female_ages, male_ages)"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 37}, {"source": ["A Mann-Whitney U test was performed:\n", "\n", "  + $H_0$: The median age of female passengers is equal to the mean age of male passengers.\n", "  + $H_1$: The median age of female passengers is not equal to the mean age of male passengers.\n", "  \n", "We obtained a p-value of $0.0348\\dots$, and so the 1% level null hypothesis cannot be rejected, and there is not enough evidence to say that the median ages of the genders differ.\n"], "cell_type": "markdown", "metadata": {}}, {"source": ["Now using `scipy.optimize`, let's see how we can minimise some function arbitrary function:\n", "\n", "$\n", "f(x, y) = \\frac{1}{3} (x + 1)^2 + (y - 3)^2 - |xy|\n", "$\n", "\n", "First define this function as a Python function:"], "cell_type": "markdown", "metadata": {}}, {"source": ["def f(args):\n", "    x, y = args\n", "    return (1/3) * ((x + 1) ** 2) + ((y - 3) ** 2) - abs(x * y)"], "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "execution_count": 38}, {"source": ["f([5, 6]), f([8, 8]), f([-4, -3])"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 39}, {"source": ["import scipy.optimize\n", "scipy.optimize.minimize(f, [0, 0])  # Give it x=0, y=0 as initial guesses"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 40}, {"source": ["and this gives us the optimal values of $x = -22$ and $y = 14$."], "cell_type": "markdown", "metadata": {}}, {"source": ["# Scikit-learn\n", "\n", "The final library we will look at is scikit-learn. This is Python's machine learning library. It can implement a wide number of machine learning algorithms, but here we'll just demonstrate a clustering algorithm.\n", "\n", "First import a data set to demonstrate on (which can be downloaded [here](/assets/plants.csv)):"], "cell_type": "markdown", "metadata": {}}, {"source": ["{% highlight python %}\n", ">>> data = pd.read_csv('plants.csv')\n", ">>> data.head()\n", "{% endhighlight %}\n", "\n", "![](/assets/sklearn-unclustered.png)"], "cell_type": "raw", "metadata": {}}, {"source": ["This has observations of plants with their height and weight recorded. A plot will show more information:"], "cell_type": "markdown", "metadata": {}}, {"source": ["plt.scatter(data['Height'], data['Weight'])\n", "plt.show()"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 42}, {"source": ["plt.scatter(data['Height'], data['Weight'])\n", "plt.savefig('../../assets/plants-unclustered.png')"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 43}, {"source": ["![](/assets/plants-unclustered.png)"], "cell_type": "markdown", "metadata": {}}, {"source": ["We can see there are four natural groupings. We'll use k-means clustering to categorise these:"], "cell_type": "markdown", "metadata": {}}, {"source": ["import sklearn.cluster\n", "kmeans = sklearn.cluster.KMeans(n_clusters=4).fit(data)\n", "data['Cluster'] = kmeans.predict(data)"], "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "execution_count": 44}, {"source": ["{% highlight python %}\n", ">>> data.head()\n", "{% endhighlight %}\n", "\n", "![](/assets/sklearn-clustered.png)"], "cell_type": "raw", "metadata": {}}, {"source": ["plt.scatter(data['Height'], data['Weight'], c=data['Cluster'], cmap='viridis')\n", "plt.show()"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 46}, {"source": ["![](/assets/plants-clustered.png)"], "cell_type": "markdown", "metadata": {}}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"nbconvert_exporter": "python", "version": "3.5.4", "name": "python", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "mimetype": "text/x-python"}}}